##Summary

###(i) Reference: Florian Gross, Gordon Fraser, Andreas Zeller, ACM, 2012. [Search-Based System Testing: High Coverage, No False Alarms](http://dl.acm.org/citation.cfm?id=2336762). 

###(ii) Keywords:
* (ii1) **System Testing:** System testing of software or hardware is testing conducted on a complete, integrated system to evaluate the system's compliance with its specified requirements. System testing falls within the scope of black-box testing, and as such, should require no knowledge of the inner design of the code or logic.

* (ii2) **GUI Testing:** In software engineering, graphical user interface testing is the process of testing a product's graphical user interface to ensure it meets its specifications. To generate a set of test cases, test designers attempt to cover all the functionality of the system and fully exercise the GUI itself.

* (ii3) **Test Coverage:**  Test coverage refers to the degree of thoroughness or how well the suite of test cases "covers" or exercises the code.

* (ii4) **Unit Testing:** Unit testing is a software development process in which the smallest testable parts of an application, called units, are individually and independently scrutinized for proper operation. 

###(iii) Artifacts:

* (iii1) **Motivation:** Despite great progress in the field of test case generation, test case generation tools don't have a widespread usage due to their several shortcomings. One such shortcoming identified by the authors is the _oracle problem_ which occurs when test case generators do not use oracles to asses the test cases thereby only generating executions and not the test cases. The missing oracle results in failures in programs going unnoticed. Another problem is that of _infeasibility_ of the generated test cases which gives false failures and thus prohibit the widespread use of test case generation tools. These problems motivated the authors to use GUIs as filters against infeasible executions, and generate GUI events by using a search based approach to avoid the limitations of using system interface for test case generation. 

* (iii2) **Checklist:** 
  * Exploration and quantification of the problem of false failures caused by infeasible tests.
  * Demonstration of coverage driven generation of test suites through a GUI by the use of a new testing tool, EXSYST.
  * Description of the technical foundations of EXSYST i.e. the use of search-based system testing, which uses system test generation to maximize test quality based on coverage metrics, while avoiding false failures by construction.
  * Evaluation of the proposed methodology on a standard suite of five Java programs to show better coverage achieved by the proposed method as against state-of-the-art unit or GUI test generators.

* (iii3) **Informative Visualizations:** 
  * Figure 1: Discovering new application behavior leads to the addition of new states and transitions to the UI model.
  ![Figure 1](https://cloud.githubusercontent.com/assets/7557398/10932788/ac67f84c-82a1-11e5-9515-156cca8e4534.jpg)
  * Figure 2: Branch coverage achieved on the four case study applications where all tools succeeded for different types of code.
  ![Figure 2](https://cloud.githubusercontent.com/assets/7557398/10932800/bf44a64a-82a1-11e5-9726-6978e9c197dd.jpg)

* (iii4) **Future Work:** In the paper the authors propose to focus on the following areas in the future -
  * _Test carving:_ A technique to record and extract unit tests from system tests, if applied to the executions generated by EXSYST could allow to combine the efficiency of unit testing while retaining true failures.
  * _Alternate GUIs:_ Alternate GUIs and platforms such as Mobile phone and touchscreen devices may prove a far more valuable application ground than Java/Swing currently used in the study.
  * _Alternate system layers:_ Alternate system layers besides GUIs could provide alternate handles for providing system inputs, thus exploring the solution to the the question is whether search-based techniques could again discover the relations between input features and code features.
  * _Dynamic specification mining:_ It infers program models from executions. The more executions observed, the more accurate
the mined models become; infeasible executions, on the other hand, spoil the resulting models. Techniques that leverage
test case generation for specification mining benefit from realistic executions.
  * _Feature location:_ It attempts to locate features in code that serve a given concern. With generated realistic executions, dynamic techniques could be used to accurately locate code fragments tied to a particular concept in the user interface or otherwise structured input.
  
###(v) **Suggested Improvements:**
* (v1) For the long running tests performed by authors, Randoop crashed and hence could not be compared with other tools.  Instead of Randoop tools such as CUTE, Pex could have been used for the comparison.
* (v2) The reason could have been mentioned for choosing specifically those five study subjects for testing and evaluation purposes.
* (v3) Other coverage criteria besides branch coverage, such as statement and condition coverage could have been used for a more holistic evaluation.

###(vi) **Connection to other papers:**
The proposed approach EXSYST extends the EVOSUITE tool proposed in _Evolutionary Generation of Whole Test Suites_ by Fraser and Arcuri, which performs search at the API level; EXSYST shares the fitness function with EVOSUITE, but uses its own representation and search operators.


